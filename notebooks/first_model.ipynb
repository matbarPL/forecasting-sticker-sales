{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from pyspark.sql.functions import col, year, month, dayofmonth, dayofweek, when\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = catalog.load(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = catalog.load(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.withColumn('year', year(col('date'))) \\\n",
    "        .withColumn('month', month(col('date'))) \\\n",
    "        .withColumn('day', dayofmonth(col('date'))) \\\n",
    "        .withColumn('day_of_week', dayofweek(col('date'))) \\\n",
    "        .withColumn('is_weekend', when(col('day_of_week') >= 6, 1).otherwise(0))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mape',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-2, 10),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-2, 10)\n",
    "    }\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dval = lgb.Dataset(X_val, label=y_val, reference=dtrain)\n",
    "\n",
    "    model = lgb.train(param, dtrain, valid_sets=[dval], callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(50)])\n",
    "\n",
    "    y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "train_df = preprocess_data(train_df)\n",
    "\n",
    "# Convert to Pandas DataFrame for compatibility with LightGBM and Optuna\n",
    "train_pd = train_df.toPandas()\n",
    "\n",
    "# Handle missing values by filling them with zeros or another strategy\n",
    "train_pd.fillna(0, inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in ['country', 'store', 'product']:\n",
    "    le = LabelEncoder()\n",
    "    train_pd[column] = le.fit_transform(train_pd[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "features = ['country', 'store', 'product', 'year', 'month', 'day', 'day_of_week', 'is_weekend']\n",
    "target = 'num_sold'\n",
    "\n",
    "X = train_pd[features]\n",
    "y = train_pd[target]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a study object and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:', study.best_params)\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "best_params = study.best_params\n",
    "best_params['n_estimators'] = 1000\n",
    "\n",
    "final_model = lgb.LGBMRegressor(**best_params)\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = preprocess_data(test_df)\n",
    "test_pd = test_df.toPandas()\n",
    "\n",
    "# Handle missing values in test data\n",
    "test_pd.fillna(0, inplace=True)\n",
    "\n",
    "# Encode categorical features in test data\n",
    "for column in ['country', 'store', 'product']:\n",
    "    le = label_encoders[column]\n",
    "    test_pd[column] = le.transform(test_pd[column])\n",
    "\n",
    "X_test = test_pd[features]\n",
    "\n",
    "# Predict and prepare the submission file\n",
    "test_pd['num_sold'] = final_model.predict(X_test)\n",
    "# Convert predictions to integers\n",
    "test_pd['num_sold'] = test_pd['num_sold'].round().astype(int)\n",
    "submission = test_pd[['id', 'num_sold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../data/07_model_output/my_first_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a cell for auditing final_model on train and test datasets\n",
    "\n",
    "# Calculate predictions for both training and test datasets\n",
    "train_predictions = final_model.predict(X).round().astype(int)\n",
    "test_predictions = final_model.predict(X_test).round().astype(int)\n",
    "\n",
    "# Calculate MAPE for training dataset\n",
    "train_mape = mean_absolute_percentage_error(y, train_predictions)\n",
    "\n",
    "# Calculate MAPE for test dataset\n",
    "test_mape = mean_absolute_percentage_error(test_pd[target], test_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training MAPE: {train_mape:.4f}\")\n",
    "print(f\"Test MAPE: {test_mape:.4f}\")\n",
    "\n",
    "# You can also visualize the results if needed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plotting training predictions\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y, train_predictions, alpha=0.3)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Training Data')\n",
    "\n",
    "# Plotting test predictions\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(test_pd[target], test_predictions, alpha=0.3)\n",
    "plt.plot([test_pd[target].min(), test_pd[target].max()], [test_pd[target].min(), test_pd[target].max()], 'r', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Test Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (forecasting_sticker_sales)",
   "language": "python",
   "name": "kedro_forecasting_sticker_sales"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
